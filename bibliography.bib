@article{krizhevsky2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	journal={Advances in neural information processing systems},
	volume={25},
	pages={1097--1105},
	year={2012}
}

@misc{crisp1996,
 author = {CRISP-DM},
 year = {1996},
 title = {Cross Industry Process---Data Mining},
 url = {http://www.crisp-dm.org},
 urldate = {2016-08-03}
}

% This file was created with Citavi 6.3.0.0

@article{Shearer2000,
 author = {Shearer, C.},
 year = {2000},
 title = {The CRISP-DM model: the new blueprint for data mining},
 pages = {13--22},
 volume = {5},
 number = {4},
 journal = {Journal of data warehousing}
}

@inproceedings{10.1145/3339252.3339281,
	author = {Hittmeir, Markus and Ekelhart, Andreas and Mayer, Rudolf},
	title = {On the Utility of Synthetic Data: An Empirical Evaluation on Machine Learning Tasks},
	year = {2019},
	isbn = {9781450371643},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3339252.3339281},
	doi = {10.1145/3339252.3339281},
	abstract = {With the recent advances and increasing activities in data mining and analysis, the
	protection of the privacy of individuals is crucial. Several approaches address this
	concern, from techniques like data anonymisation to secure, non-disclosive computation,
	all of which have their specific strengths and weaknesses, depending on the specific
	requirements. A slightly different approach is the generation of synthetic data, which
	tries to preserve the overall properties and characteristics of the original data
	without revealing information about actual individual data samples. The promise is
	that, for most purposes, models trained on the synthetic data instead of the real
	data do not show a significant loss of performance. In this paper, we give an overview
	on currently available approaches for synthetic data generation, and empirically evaluate
	the utility of the generated synthetic data by testing them on a number of supervised
	machine learning tasks on several publicly available datasets.},
	booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
	articleno = {29},
	numpages = {6},
	keywords = {Synthetic Data, Machine Learning, Privacy-Preserving Data Mining},
	location = {Canterbury, CA, United Kingdom},
	series = {ARES '19}
}

@article{mice,
	author = {Buuren, Stef and Groothuis-Oudshoorn, Catharina},
	year = {2011},
	month = {12},
	pages = {},
	title = {MICE: Multivariate Imputation by Chained Equations in R},
	volume = {45},
	journal = {Journal of Statistical Software},
	doi = {10.18637/jss.v045.i03}
}

@article {norvig_eod,
	author = {F. Pereira and P. Norvig and A. Halevy},
	journal = {IEEE Intelligent Systems},
	title = {The Unreasonable Effectiveness of Data},
	year = {2009},
	volume = {24},
	number = {02},
	issn = {1941-1294},
	pages = {8-12},
	keywords = {machine learning;very large data bases;semantic web},
	doi = {10.1109/MIS.2009.36},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA},
	month = {mar}
}

@misc{buitinck2013api,
	title={API design for machine learning software: experiences from the scikit-learn project}, 
	author={Lars Buitinck and Gilles Louppe and Mathieu Blondel and Fabian Pedregosa and Andreas Mueller and Olivier Grisel and Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort and Jaques Grobler and Robert Layton and Jake Vanderplas and Arnaud Joly and Brian Holt and Gaël Varoquaux},
	year={2013},
	eprint={1309.0238},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}


@misc{smith_1cycle,
	title={A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay}, 
	author={Leslie N. Smith},
	year={2018},
	eprint={1803.09820},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{goodfellow2014generative,
	title={Generative Adversarial Networks}, 
	author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
	year={2014},
	eprint={1406.2661},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{mnist,
	title={The mnist database of handwritten digit images for machine learning research},
	author={Deng, Li},
	journal={IEEE Signal Processing Magazine},
	volume={29},
	number={6},
	pages={141--142},
	year={2012},
	publisher={IEEE}
}

@inproceedings{titanic,
	author = {Farag, Nadine and Hassan, Ghada},
	title = {Predicting the Survivors of the Titanic Kaggle, Machine Learning From Disaster},
	year = {2018},
	isbn = {9781450364690},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3220267.3220282},
	doi = {10.1145/3220267.3220282},
	abstract = {April 14th, 1912 was very unfortunate for the most powerful ship ever built at that
	time, the Titanic. Grievously, 1503 out of 2203 passengers perished the sinking, but
	the rationale behind survival still remains a question mark. In efforts to study the
	Titanic passengers; Kaggle, a popular data science website, assembled information
	about each passenger back in the days of the Titanic into a dataset, and made it available
	for a competition titled: "Titanic: Machine Learning from Disaster." This research
	aims to use machine learning techniques on the Titanic data to analyze the data for
	classification and to predict the survival of the Titanic passengers by using data-mining
	algorithms; specifically Decision Trees and Na\"{\i}ve Bayes. The prediction and efficiency
	of these algorithms depend greatly on data analysis and the model. The paper presents
	an implementation which combines the benefits of feature selection and machine learning
	to accurately select and distinguish characteristics of passengers' age, class, cabin,
	and port of embarkation then consequently infer an authentic model for an accurate
	prediction. The data-set is described and the implementation details and prediction
	results are presented then compared to other results. The Decision Tree algorithm
	has accurately predicted 90.01% of the survival of passengers, while the Gaussian
	Na\"{\i}ve Bayes witnessed 92.52% accuracy in prediction.},
	booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
	pages = {32–37},
	numpages = {6},
	keywords = {Na\"{\i}ve Bayes, Machine Learning, Decision Trees, Supervised Learning, Kaggle, Data Mining},
	location = {Cairo, Egypt},
	series = {ICSIE '18}
}

@misc{gan_continual_learning,
	title={Generative Adversarial Network Training is a Continual Learning Problem}, 
	author={Kevin J Liang and Chunyuan Li and Guoyin Wang and Lawrence Carin},
	year={2018},
	eprint={1811.11083},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@incollection{catastrophic_forgetting,
	title={Catastrophic interference in connectionist networks: The sequential learning problem},
	author={McCloskey, Michael and Cohen, Neal J},
	booktitle={Psychology of learning and motivation},
	volume={24},
	pages={109--165},
	year={1989},
	publisher={Elsevier}
}

@misc{mode_collapse,
	title={Mode Regularized Generative Adversarial Networks}, 
	author={Tong Che and Yanran Li and Athul Paul Jacob and Yoshua Bengio and Wenjie Li},
	year={2017},
	eprint={1612.02136},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{dcgan,
	title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}, 
	author={Alec Radford and Luke Metz and Soumith Chintala},
	year={2016},
	eprint={1511.06434},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{oversampling_gan,
	author = {Suh, Sungho and Lee, Haebom and Jo, Jun and Lukowicz, Paul and Lee, Yong},
	year = {2019},
	month = {02},
	pages = {746},
	title = {Generative Oversampling Method for Imbalanced Data on Bearing Fault Detection and Diagnosis},
	volume = {9},
	journal = {Applied Sciences},
	doi = {10.3390/app9040746}
}

@misc{batchnorm,
	title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}, 
	author={Sergey Ioffe and Christian Szegedy},
	year={2015},
	eprint={1502.03167},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{convolution_arithmetic,
	title={A guide to convolution arithmetic for deep learning}, 
	author={Vincent Dumoulin and Francesco Visin},
	year={2018},
	eprint={1603.07285},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@misc{arjovsky2017wasserstein,
	title={Wasserstein GAN}, 
	author={Martin Arjovsky and Soumith Chintala and Léon Bottou},
	year={2017},
	eprint={1701.07875},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@misc{gulrajani2017improved,
	title={Improved Training of Wasserstein GANs}, 
	author={Ishaan Gulrajani and Faruk Ahmed and Martin Arjovsky and Vincent Dumoulin and Aaron Courville},
	year={2017},
	eprint={1704.00028},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{fan2008liblinear,
	title={LIBLINEAR: A library for large linear classification},
	author={Fan, Rong-En and Chang, Kai-Wei and Hsieh, Cho-Jui and Wang, Xiang-Rui and Lin, Chih-Jen},
	journal={the Journal of machine Learning research},
	volume={9},
	pages={1871--1874},
	year={2008},
	publisher={JMLR. org}
}

@article{vapnik1995support,
	title={Support vector machines},
	author={Vapnik, Vladimir and Guyon, Isabel and Hastie, Trevor},
	journal={Mach. Learn},
	volume={20},
	number={3},
	pages={273--297},
	year={1995}
}

@article{quinlan1986induction,
	title={Induction of decision trees},
	author={Quinlan, J. Ross},
	journal={Machine learning},
	volume={1},
	number={1},
	pages={81--106},
	year={1986},
	publisher={Springer}
}

@article{winequality,
	title = {Modeling wine preferences by data mining from physicochemical properties},
	journal = {Decision Support Systems},
	volume = {47},
	number = {4},
	pages = {547-553},
	year = {2009},
	note = {Smart Business Networks: Concepts and Empirical Evidence},
	issn = {0167-9236},
	doi = {https://doi.org/10.1016/j.dss.2009.05.016},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923609001377},
	author = {Paulo Cortez and António Cerdeira and Fernando Almeida and Telmo Matos and José Reis},
	keywords = {Sensory preferences, Regression, Variable selection, Model selection, Support vector machines, Neural networks},
	abstract = {We propose a data mining approach to predict human wine taste preferences that is based on easily available analytical tests at the certification step. A large dataset (when compared to other studies in this domain) is considered, with white and red vinho verde samples (from Portugal). Three regression techniques were applied, under a computationally efficient procedure that performs simultaneous variable and model selection. The support vector machine achieved promising results, outperforming the multiple regression and neural network methods. Such model is useful to support the oenologist wine tasting evaluations and improve wine production. Furthermore, similar techniques can help in target marketing by modeling consumer tastes from niche markets.}
}