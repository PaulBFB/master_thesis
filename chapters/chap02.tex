\chapter{Data augmentation and synthesis in other Areas}
\label{chapter:synthetic_data}

Due to the importance of the amount of training data available and its' large impact on machine learning outcomes, using existing training data to maximum effect is a topic that has been approached from multiple sides. More established approaches involve K-Fold Crossvalidation as explored by \cite{kfold} and \ac{bagging}. 

In these approaches, broadly speaking, the available data is sub-sampled in different ways to simulate the presence of multiple - subtly differing - training sets, which makes them analogous to \ac{nn} dropout as described by \cite{srivastava2014dropout} in their paper and ensemble methods as described by \cite{dietterich2000ensemble}.

\textbf{Creating} entirely new synthetic training data or \textbf{altering} existing data to fit machine learning models is separate area of research. 

\pagebreak

\section{Synthetic Data for Privacy / Data Protection}

A significant amount of the impetus behind this area of research stems from privacy concerns and attendant legislation. 
Especially noteworthy here is of course the \ac{GDPR} which imposes potentially devastating penalties on the misuse of data regarding to natural persons ("natural person" in the legal sense, as opposed to a legal person such as a corporation). 

A full discussion of data privacy is out of scope in this paper, but the motivation to sidestep concerns involving specific persons which arises from the potential sanctions arising from the \ac{GDPR} or \ac{HIPAA} and similar legislation by data anonymization is clear and understandable.

\cite{el2020practical} explores the topic well in his book. As illustrated here:

\fig{img/synthetic_data_el2020}{from \cite{el2020practical}}{fig:synthetic_el}{.8}

As the graphic shows quite succinctly, the logical process involves extracting relevant patterns from the original data, explicitly or implicitly, and then producing new data which preserves these patterns. 
The generated data may then be used, without legal or ethical concerns regarding the privacy interests of the subjects of the original data, in order to extract insights and conduct research.

The implicit assumption in this concept is, however: that the patterns which are relevant may be known beforehand and/or separated from the types of research conducted on the new data. More directly put, extracting patterns from a table of data with some attributes may be fairly trivial since there is only a limited if not always small number of interrelations possible between multiple attributes. 
The situation changes dramatically if the data in question is stored in a relational database or distributed system, or is semi-structured or unstructured.

In these cases, it may be difficult to even identify patterns in the data which need to be preserved in order to facilitate its' use in possible use cases in the future.

This assumption may not always hold true but there is existing research which has been conducted to mitigate this problem.

\pagebreak

\subsection{Synthetic Data Vault}

\cite{patki2016synthetic} describe an interesting approach to solve the issue of anonymization of an entire relational database specifically. 

Their approach, briefly, proposes to model relations between tables specifically, in an iterative manner:

\fig{img/synthetic_data_vault}{from \cite{patki2016synthetic}}{fig:synthetic_data_vault}{.8}

The model of the database then exposes these tables via an \ac{API} to be queried and generates synthetic tables based on the tables queried and their interrelations.
In their paper \cite{patki2016synthetic} assess the efficacy of their approach by crowd-sourcing prediction tasks on datasets generated with their approach to data scientists and find that in over 50\% of cases 
there was no significant difference in predictive power between features generated on the original dataset vs. generated data (an independent comparison to another approach is found here: \ref{subsection:efficacy}).

\pagebreak

\subsection{DataSynthesizer}

\cite{ping2017datasynthesizer} propose a method with a stronger focus on tabular data in their paper.

Their method, the DataSynthesizer focuses more strongly on the inference of data types, supporting most common types

\begin{itemize}
	\item integer
	\item float
	\item string
	\item datetime
\end{itemize} 

and then infers their meaning from there, attempting to recognize whether an attribute describes a category it it is a string for example.

\pagebreak

The resulting generation and assessment process is illustrated here:

\fig{img/data_synthesizer}{from \cite{ping2017datasynthesizer}}{fig:data_synthesizer}{.8}

It is really quite an elegant approach which attempts to produce a statistically similar generated dataset.

\clearpage

\subsection{Efficacy of synthesized data}

\label{subsection:efficacy}

\cite{ares_utility} compare these two approaches to each other in detail and assess their efficacy in creating classification models in comparison to each other and to real data:

\fig{img/ares}{showing the decision boundary of an \ac{SVM} classifier trained on data generated on original data (left), data generated using the \ac{DS} (middle) and \ac{SDV} (right) from \cite{ares_utility}}{fig:ares}{1}

As a note here, \cite{ares_utility} used tabular datasets for evaluation 

\pagebreak

\section{Data Enhancement for Image Data}

When training \acp{nn} for image classification, (source) a common practice is \textbf{data augmentation}, a range of random transformation applied to images in order to synthetically increase the breadth of data that the model is exposed to. 
Such operations include 
\begin{itemize}
	\item rotation
	\item shearing
	\item zoom
	\item height \& width shift
\end{itemize}

effectively, these operations transform an Image while preserving the underlying signals in the data. However, with other types of data this might be possible. Attributes of another dataset may not be feasibly 'shifted' in one direction or another without fundamentally changing the signal and misleading the model.

\textbf{note - the infeasibility of pretraining on non-image datasets - representations of the visual world}

\section{SMOTE}
