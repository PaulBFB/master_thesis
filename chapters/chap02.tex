\chapter{Data augmentation and synthesis in other Areas}
\label{chapter:synthetic_data}

Due to the importance of the amount of training data available and its' large impact on machine learning outcomes, using existing training data to maximum effect is a topic that has been approached from multiple sides. More established approaches involve K-Fold Crossvalidation as explored by \cite{kfold} and \ac{bagging}. 

In these approaches, broadly speaking, the available data is sub-sampled in different ways to simulate the presence of multiple - subtly differing - training sets, which makes them analogous to \ac{nn} dropout as described by \cite{srivastava2014dropout} in their paper and ensemble methods as described by \cite{dietterich2000ensemble}.

\textbf{Creating} entirely new synthetic training data or \textbf{altering} existing data to fit machine learning models is separate area of research. 

\pagebreak

\section{Synthetic Data for Privacy / Data Protection}

A significant amount of the impetus behind this area of research stems from privacy concerns and attendant legislation. 
Especially noteworthy here is of course the \ac{GDPR} which imposes potentially devastating penalties on the misuse of data regarding to natural persons ("natural person" in the legal sense, as opposed to a legal person such as a corporation). 

A full discussion of data privacy is out of scope in this paper, but the motivation to sidestep concerns involving specific persons which arises from the potential sanctions arising from the \ac{GDPR} or \ac{HIPAA} and similar legislation by data anonymization is clear and understandable.

\cite{el2020practical} explores the topic well in his book. As illustrated here:

\fig{img/synthetic_data_el2020}{from \cite{el2020practical}}{fig:synthetic_el}{.8}

As the graphic shows quite succinctly, the logical process involves extracting relevant patterns from the original data, explicitly or implicitly, and then producing new data which preserves these patterns. 
The generated data may then be used, without legal or ethical concerns regarding the privacy interests of the subjects of the original data, in order to extract insights and conduct research.

The implicit assumption in this concept is, however: that the patterns which are relevant may be known beforehand and/or separated from the types of research conducted on the new data. More directly put, extracting patterns from a table of data with some attributes may be fairly trivial since there is only a limited if not always small number of interrelations possible between multiple attributes. 
The situation changes dramatically if the data in question is stored in a relational database or distributed system, or is semi-structured or unstructured.

In these cases, it may be difficult to even identify patterns in the data which need to be preserved in order to facilitate its' use in possible use cases in the future.

This assumption may not always hold true but there is existing research which has been conducted to mitigate this problem.

\pagebreak

\subsection{Synthetic Data Vault}

\cite{patki2016synthetic} describe an interesting approach to solve the issue of anonymization of an entire relational database specifically. 

Their approach, briefly, proposes to model relations between tables specifically, in an iterative manner:

\fig{img/synthetic_data_vault}{from \cite{patki2016synthetic}}{fig:synthetic_data_vault}{.8}

The model of the database then exposes these tables via an \ac{API} to be queried and generates synthetic tables based on the tables queried and their interrelations.
In their paper \cite{patki2016synthetic} assess the efficacy of their approach by crowd-sourcing prediction tasks on datasets generated with their approach to data scientists and find that in over 50\% of cases 
there was no significant difference in predictive power between features generated on the original dataset vs. generated data (an independent comparison to another approach is found here: \ref{subsection:efficacy}).

\pagebreak

\subsection{DataSynthesizer}
\label{subsection:datasynthesizer}

\cite{ping2017datasynthesizer} propose a method with a stronger focus on tabular data in their paper.

Their method, the DataSynthesizer focuses more strongly on the inference of data types, supporting most common types

\begin{itemize}
	\item integer
	\item float
	\item string
	\item datetime
\end{itemize} 

and then infers their meaning from there, attempting to recognize whether an attribute describes a category it it is a string for example.

\pagebreak

The resulting generation and assessment process is illustrated here:

\fig{img/data_synthesizer}{from \cite{ping2017datasynthesizer}}{fig:data_synthesizer}{.8}

It is really quite an elegant approach which attempts to produce a statistically similar generated dataset.

\clearpage

\subsection{Efficacy of synthesized data}

\label{subsection:efficacy}

\cite{ares_utility} compare these two approaches to each other in detail and assess their efficacy in creating classification models in comparison to each other and to real data:

\fig{img/ares}{showing the decision boundary of an \ac{SVM} classifier trained on data generated on original data (left), data generated using the \ac{DS} (middle) and \ac{SDV} (right) from \cite{ares_utility}}{fig:ares}{1}

As a note here, \cite{ares_utility} used tabular datasets for evaluation which plays to the strength of the \ac{DS} approach. Some further notes in the conclusion, their paper is quite pertinent to the objective here.

\pagebreak

\section{Synthetic Minority Oversampling Technique}
\label{section:smote}

A popular approach in which synthetic data is used, \ac{SMOTE} focuses on strongly imbalanced datasets. As \cite{smote} argue in their paper, real-world data is often unbalanced in such a way in which the case which needs to be detected constitutes only an extremely small part of the data, while detection of these samples is critical. Noteworthy examples include the detection of cancer and fraudulent bank transactions.

The focus of \ac{SMOTE} is on the identification of interesting feature spaces, and not only sampling from these regions with small perturbations in the data, while undersampling the majority class. 
Interestingly, this approach was inspired in part by work on data augmentation in image data (in the next section \ref{section:image_augmentation}).

The salient difference here is that while image augmentation follows vector operations (in most cases) \ac{SMOTE} searches for the nearest neighbors in the feature spaces in the rare class and "interpolates" synthetic samples along the lines between nearest neighbors in the rare class.

Furthermore, in the original paper \cite{smote} evaluate \ac{SMOTE} using another dataset that is of interest, the Pima Indians Diabetes dataset described by \cite{diabetes}.

\pagebreak

Due to thee fact that the objective here is the detection of a rare class, the authors evaluate their approach using the \ac{ROC} \ac{AUC} as seen here:

\fig{img/smote_pima}{from \cite{smote}}{fig:pima_smote}{.8}

Comparison to the relevant section here: \ref{subsection:pima}
Note that while interesting, \ac{SMOTE} is a strongly opinionated approach that would probably not be suited to application to balanced datasets.

\clearpage

\section{Data Augmentation for Image Data}
\label{section:image_augmentation}

While the approaches for synthetic data generation discussed in previous sections involve the addition of noise into the dataset (specifically \ac{SDV} as proposed by \cite{patki2016synthetic} and the interpolation in \ac{SMOTE} proposed by \cite{smote}), they do not constitute the alteration of existing training data proposed by \cite{image_augmentation}.

On a conceptual level, image data is quite distinct in the way that it includes a notion of locality (neighboring pixels are in relation to one another) and that it lends itself to rapid visual assessment by humans. In contrast to vectors of attributes constituted by other datasets, humans are capable of immediately assess whether or not an image representation has been preserver after alteration. This eliminates 

When training \acp{nn} for image classification therefore, a common practice is \textbf{data augmentation}, a range of semi-random transformations applied to images in order to artificially increase the breadth of data that the model is exposed to while presenting the underlying meaning. 

Such operations include:
\begin{itemize}
	\item rotation
	\item shearing
	\item zoom
	\item height \& width shift
\end{itemize}

effectively, these operations transform an Image while preserving the underlying signals in the data. 

\pagebreak

To illustrate the effect, examples can be seen here:

\fig{img/image_augmentation}{showing classical image transformations from \cite{perez2017effectiveness}}{fig:image_augmentation}{1}

While These transformations seem trivial to a human, it is important to note that effectively all pixels in these images are changed and to a machine learning model, each perturbation represents an entirely new observation. 
Only the underlying meaning has been preserved, forcing the network to learn representations of the subjects in the data. As a note, in this very paper \cite{perez2017effectiveness} mention image augmentation with style-transfer \acp{GAN}, a currently very active field of study.

However, with other types of data this might not be possible. Attributes of another dataset may not be feasibly 'shifted' in one direction or another without fundamentally changing the signal and misleading the model. Furthermore, humans cannot immediately assess the loss of this meaning in the data, which is why other methods of creating synthetic data (such as \ac{DS} in particular \ref{subsection:datasynthesizer}) have to rely on statistical indicators of similarity to assess the actual quality of the data.

As alluded to in the previous section, the approach described by \cite{image_augmentation} partly inspired \ac{SMOTE} noted here: \ref{section:smote}.

A large comprehensive survey on the effectiveness on such techniques was composed by \cite{shorten2019survey}, comparing the efficacy of a large array of variations.
